{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNXFaIyav1RuvK5WZMEMGb8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArpitKadam/ColabNotebooks/blob/main/Text_Generation_with_GPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "WwvzAp7Ftvhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2-large\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2-large\").to(device)"
      ],
      "metadata": {
        "id": "tvkhQ9ELm8_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gE4VUSYQm7mQ",
        "outputId": "e47b8bdf-e5b9-4698-df5c-1630721d61f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 1280)\n",
              "    (wpe): Embedding(1024, 1280)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-35): 36 x GPT2Block(\n",
              "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D(nf=3840, nx=1280)\n",
              "          (c_proj): Conv1D(nf=1280, nx=1280)\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D(nf=5120, nx=1280)\n",
              "          (c_proj): Conv1D(nf=1280, nx=5120)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1280, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BEAM SEARCH**"
      ],
      "metadata": {
        "id": "5tkLPtARyIsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"I am really impressed by your work and\"\n",
        "max_length = 256\n",
        "\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\").to(device)"
      ],
      "metadata": {
        "id": "MLmoUIoWmxe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJQd0cWxmsNf",
        "outputId": "5ce347f5-4867-4c77-9fd4-13e291e3a727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[   40,   716,  1107, 12617,   416,   534,   670,   290]],\n",
              "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genrated_tensors = model.generate(\n",
        "    input_ids['input_ids'],\n",
        "    max_length=max_length,\n",
        "    num_beams=5,\n",
        "    do_sample=False,\n",
        "    no_repeat_ngram_size=3\n",
        "  )\n",
        "\n",
        "print(genrated_tensors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAgYpIGEmsLP",
        "outputId": "0a8eb0cc-1435-434c-d4d7-5ac90e5606bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   40,   716,  1107, 12617,   416,   534,   670,   290,   314,  2911,\n",
            "           284,   766,   517,   286,   340,   287,   262,  2003,    13,   198,\n",
            "           198, 10449,   345,   845,   881,   329,   477,   534,  1327,   670,\n",
            "           290, 22445,     0,   198,   198, 13014, 13957,    11,   198,   198,\n",
            "            50,  1765,   459,   666,   198,   198, 17250, 26190,    11,   628,\n",
            "           198,  9690,   329,  2263,   262,   640,   284,  3280,   616,  2683,\n",
            "            13,   628,   198,  5962,   286,   477,    11,   314,   561,   588,\n",
            "           284,  5875,   345,   329,   477,   262,   670,   345,   423,  1760,\n",
            "           287,   262,  1613,  1178,   812,    13,   314,   423,   587,   257,\n",
            "          4336,   286,   534,   670,   329,   257,   890,   640,    11,   290,\n",
            "           314,   716,   845,  3772,   284,   766,   326,   345,   389,   991,\n",
            "          1762,   319,   340,    13,   314,   561,   635,   588,   284,   910,\n",
            "           326,   314,   716,   257,  3236,  4336,   286,   345,   290,   534,\n",
            "           670,    13,   921,   389,   530,   286,   262,   749, 12356,  7912,\n",
            "           314,   423,  1683,  1282,  1973,    11,   290,   340,   318,  1049,\n",
            "           284,   766,   345,  2555,   284,  4574,   262, 13215,   286,   644,\n",
            "           460,   307,  1760,   351,   257,   513,    35,  2746,    13,   314,\n",
            "          2911,   326,   345,   481,  2555,   284,   670,   319,   428,  1628,\n",
            "            11,   290,   326,   345,   460,  2555,   284,   466,   523,   351,\n",
            "           262,   976,  7506,   290, 22445,   326,   345,   423,  3402,   329,\n",
            "           262,  1613,  3155,   286,   812,    13,  6952,   345,   757,   329,\n",
            "           477,   326,   345,   466,    11,   290,  5875,   345,   284,   477,\n",
            "           286,   262,   661,   508,   423,  4193,   345,  1863,   262,   835,\n",
            "            13,   314,   804,  2651,   284,  4379,   644,   345,  1282,   510,\n",
            "           351,  1306,     0,   628,   198,  6385, 38015,    11,   628,    11,\n",
            "           198,    42,   776, 20042,   198,   198]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = tokenizer.decode(genrated_tensors[0], skip_special_tokens=True)\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "-1dZ9SDwk2vS",
        "outputId": "1374471c-a203-415c-cfa3-14a68bd9f789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I am really impressed by your work and I hope to see more of it in the future.\\n\\nThank you very much for all your hard work and dedication!\\n\\nBest regards,\\n\\nSebastian\\n\\nHi Sebastian,\\n\\n\\nThanks for taking the time to answer my questions.\\n\\n\\nFirst of all, I would like to thank you for all the work you have done in the past few years. I have been a fan of your work for a long time, and I am very happy to see that you are still working on it. I would also like to say that I am a huge fan of you and your work. You are one of the most talented artists I have ever come across, and it is great to see you continue to push the boundaries of what can be done with a 3D model. I hope that you will continue to work on this project, and that you can continue to do so with the same passion and dedication that you have shown for the past couple of years. Thank you again for all that you do, and thank you to all of the people who have helped you along the way. I look forward to seeing what you come up with next!\\n\\n\\nSincerely,\\n\\n,\\nKathleen\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r5BLeHiAwBKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NUCLEUS SEARCH**"
      ],
      "metadata": {
        "id": "pL_D_jamyOXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"I am really impressed by your work and\"\n",
        "max_length = 256\n",
        "\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\").to(device)"
      ],
      "metadata": {
        "id": "Y4icot6EyWHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genrated_tensors = model.generate(\n",
        "    input_ids['input_ids'],\n",
        "    max_length=max_length,\n",
        "    do_sample=True,\n",
        "    top_p=0.9\n",
        "  )\n",
        "\n",
        "print(genrated_tensors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kqza6kJCyWFF",
        "outputId": "e43a8bf8-8de4-4b85-b1f3-5294cb8eb5b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   40,  1107, 18869,  5089,   428, 21551,   523,  2089,    13,  1320,\n",
            "         21551, 14071,   284,   307, 20654,   523,  2089,    13,  2011,  1310,\n",
            "         33526, 18185, 14071,   284,   307, 20654,   588,   326,   526,   198,\n",
            "           198,  3347,   714,  1254,   262,  3833,  1382,   287,   607, 18185,\n",
            "           355,   673,  5158,   290,   373,  1654,   326,   607, 18185,   373,\n",
            "          1972,  1969,   284, 10973,  2229,    13,   198,   198,     1,  2396,\n",
            "           783,   345,   821,  8066, 10973,  1165,    30,  2735,   345,   821,\n",
            "          8066, 10973,   319,   616,  9372,  1986,  1701,   198,   198,     1,\n",
            "          5812,  5770,  1399, 11752,  5770,   526,   673,  6941, 22739,    13,\n",
            "           366,  1026,  5300,   523,   922,  1399,   340,  5300,   523,   922,\n",
            "            13, 25617,  1399,   616, 40267,   338,   523,  5381,    13,   632,\n",
            "           338,   523,   922,   526,   198,   198,  3152,   257,  1402,  1461,\n",
            "           673,  2936,   262,  9476,  1382,    13,   198,   198,     1,  5812,\n",
            "          5089,   340,  5300,   523,   922,     0,  2011, 40267,  5300,   523,\n",
            "          5381,     0,   632,   338,   523,  9372,  5381,    11,   616, 40267,\n",
            "           318,   523,  5381,   526,   198,   198,  3260,   607, 23770,   673,\n",
            "          3114,   379,   607, 18185,   290,   340,   373, 41714,  9583,    13,\n",
            "          2332, 31571,   550, 18859,   503,   286,   607, 26150,   290,  4291,\n",
            "           607, 18185,    13,   198,   198,     1,  5812,   616,  5770,    11,\n",
            "           326,  5300,   523,   922,  2474,  1375, 17293,    13,   366,  5812,\n",
            "           616,  5770,    11,   326,   338,   523,  9372,   922,  2474,   198,\n",
            "           198,  9360, 18185,   936,   704,   355,   340,  2067,   284, 12035,\n",
            "            13,   632,   373, 19597,    11, 19597,    11, 19597,    11,   475,\n",
            "           673,  3521,   470,  2245,   340,    13,  1375,  2622,   284, 10973,\n",
            "           757,    13,  1375,  2622,   284, 10973,   284,  1254,   644,   673,\n",
            "           550,  2936,    11,   284,  1254,   607]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = tokenizer.decode(genrated_tensors[0], skip_special_tokens=True)\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "8dYIYYMlyWCu",
        "outputId": "a7cf6c78-5d1c-4b05-9580-b211ca523836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I really wanna fuck this bitch so bad. That bitch deserves to be fucked so bad. My little slut pussy deserves to be fucked like that.\"\\n\\nShe could feel the pressure build in her pussy as she spoke and was sure that her pussy was getting close to cumming.\\n\\n\"So now you\\'re gonna cum too? Now you\\'re gonna cum on my fucking face?\"\\n\\n\"Oh god… oh god.\" she moaned. \"It feels so good… it feels so good. Fuck… my cunt\\'s so tight. It\\'s so good.\"\\n\\nWith a small pop she felt the pleasure build.\\n\\n\"Oh fuck it feels so good! My cunt feels so tight! It\\'s so fucking tight, my cunt is so tight.\"\\n\\nAfter her orgasm she looked at her pussy and it was soaking wet. Her panties had slipped out of her vagina and onto her pussy.\\n\\n\"Oh my god, that feels so good!\" She shouted. \"Oh my god, that\\'s so fucking good!\"\\n\\nHer pussy ached as it started to heal. It was sore, sore, sore, but she couldn\\'t stop it. She needed to cum again. She needed to cum to feel what she had felt, to feel her'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T8oXxg-Wk2sr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}